{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a029a64d",
   "metadata": {},
   "source": [
    "# Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab641b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard packages\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Spotify model packages\n",
    "import spotify_data as data\n",
    "import spotify_tools as tools\n",
    "import spotify_models as models\n",
    "import spotify_metrics as metrics\n",
    "\n",
    "#allows for autoreload if import files change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab8ed9",
   "metadata": {},
   "source": [
    "# Random Choice Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8e088",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Load data and control its size since the volume of data is enormous for some machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d9baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = data.get_playlist_track_matrix()\n",
    "\n",
    "#reduce the amount of data for slower machines\n",
    "P,_ = train_test_split(P,train_size= 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0dee9",
   "metadata": {},
   "source": [
    "### Random Baseline Model\n",
    "\n",
    "As a baseline for evaluation, we introduce a simple **random model** that recommends songs uniformly at random.\n",
    "\n",
    "#### Model Description\n",
    "\n",
    "The `Spotify_Random` model does not learn from the training data. Instead, it simply selects a fixed number of songs uniformly at random from the entire catalog, without replacement. This serves as a control to help us interpret the quality of more sophisticated models.\n",
    "\n",
    "The random model is evaluated on the same test playlists as other models. Specifically, it predicts 25 songs for each playlist, and its predictions are compared to the held-out songs using several metrics:\n",
    "\n",
    "- **Accuracy score**: Measures the fraction of predicted songs that exactly match the hidden (ground-truth) continuation.\n",
    "- **Artist vibe score**: Measures the cosine similarity between predicted and hidden songs after projecting both into artist space.\n",
    "- **Album vibe score**: Same as above but in album space.\n",
    "- **Co-occurrence vibe score**: Uses a song co-occurrence matrix derived from the training data to assess how well the prediction \"feels\" like the true continuation.\n",
    "\n",
    "These metrics help establish a lower bound on performance — any reasonable model should significantly outperform this random baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fe59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = data.get_artist_track_matrix()\n",
    "B = data.get_album_track_matrix()\n",
    "\n",
    "train_playlists,test_playlists = train_test_split(P,train_size= 0.2)\n",
    "\n",
    "rnd_model = models.Spotify_Random()\n",
    "rnd_model.fit(train_playlists.shape[1])\n",
    "\n",
    "\n",
    "test_partial, test_hidden = tools.csr_col_split(test_playlists, 10,'shuffle')\n",
    "\n",
    "predictions = rnd_model.predict(test_partial.shape[0], 25)\n",
    "\n",
    "\n",
    "# Compute scores\n",
    "acc = metrics.prediction_accuracy_score(test_hidden, predictions).mean()\n",
    "artist_vibe = metrics.transform_cosine_score(test_hidden, predictions, A).mean()\n",
    "album_vibe = metrics.transform_cosine_score(test_hidden, predictions, B).mean()\n",
    "\n",
    "\n",
    "cooccur_matrix = train_playlists.T @ train_playlists\n",
    "\n",
    "vibe_score = metrics.transform_cosine_score(test_hidden, predictions, cooccur_matrix).mean()\n",
    "\n",
    "\n",
    "# Summary\n",
    "print(f\"Accuracy score:          {acc:.3f}\")\n",
    "print(f\"Artist vibe score:       {artist_vibe:.3f}\")\n",
    "print(f\"Album vibe score:        {album_vibe:.3f}\")\n",
    "print(f\"Co-occurrence vibe score:{vibe_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42643b8d",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb41298",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Load data and control its size since the volume of data is enormous for some machines.  \n",
    "We use only a small fraction of the playlist-track matrix for this experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = data.get_playlist_track_matrix()\n",
    "P,_ = train_test_split(P,train_size= 0.002)\n",
    "\n",
    "#define which exponents (alpha) you want to test\n",
    "alpha = np.linspace(0.1, 2, 20)\n",
    "fcts = [lambda x, a=a: 1/(x**a + 0.5) for a in alpha]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3c053",
   "metadata": {},
   "source": [
    "### Experiment: Evaluating KNN-Based Recommendations with Varying Distance Functions\n",
    "\n",
    "In this experiment, we evaluate a KNN-style recommendation model that predicts songs based on their proximity to a given playlist in a song co-occurrence graph. The key idea is to define a **distance function** over co-occurrence counts, parameterized by an exponent $\\alpha$:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{x^\\alpha + 0.5}\n",
    "$$\n",
    "\n",
    "This function is used to transform raw co-occurrence counts into distance-like values, where higher co-occurrence implies greater similarity. For each value of $\\alpha$, a different version of the model is trained and evaluated.\n",
    "\n",
    "#### Experimental Setup\n",
    "\n",
    "- The playlist-song matrix $P$ is split using K-fold cross-validation, with one fold per $\\alpha$ value.\n",
    "- For each fold:\n",
    "  - The model is trained on the training split using the corresponding distance function.\n",
    "  - A 10-song subset is hidden from each test playlist using random splitting.\n",
    "  - The model predicts 25 songs for each test playlist using a greedy algorithm that incrementally selects highly connected songs.\n",
    "  - Several metrics are computed to evaluate performance:\n",
    "    - **Accuracy**: Proportion of predicted songs that match hidden tracks.\n",
    "    - **Artist/Album Vibe**: Cosine similarity between predicted and hidden tracks, projected into artist or album space.\n",
    "    - **Co-occurrence Vibe**: Similarity computed using the full co-occurrence matrix.\n",
    "    - **Popularity Bias**: Histogram of predicted songs’ popularity ranks to assess bias toward popular content.\n",
    "\n",
    "Each fold corresponds to a different $\\alpha$ value, allowing us to analyze how the distance transformation affects both recommendation quality and popularity bias.\n",
    "\n",
    "This evaluation provides insight into how much influence the shape of the distance decay function has on the diversity and relevance of recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67533d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=len(alpha), shuffle=True, random_state=42)\n",
    "\n",
    "artist_matrix = data.get_artist_track_matrix()\n",
    "album_matrix = data.get_album_track_matrix()\n",
    "\n",
    "\n",
    "# Storage for metrics\n",
    "accuracy_scores = []\n",
    "artist_scores = []\n",
    "album_scores = []\n",
    "vibe_scores = []\n",
    "popularity_distributions = []\n",
    "\n",
    "\n",
    "\n",
    "for iter_num, (train_index, test_index) in enumerate(kf.split(P)):\n",
    "    t = time.time()\n",
    "    train_data = P[train_index]\n",
    "    test_data = P[test_index]\n",
    "\n",
    "    knn = models.Spotify_KNN()\n",
    "    knn.fit(train_data, fcts[iter_num])\n",
    "\n",
    "    test_partial, test_hidden = tools.csr_col_split(test_data, 10,'shuffle')\n",
    "    predictions = knn.predict(test_partial, 25)\n",
    "\n",
    "    # Compute scores\n",
    "    accuracy_scores.append(metrics.prediction_accuracy_score(test_hidden, predictions).mean())\n",
    "    artist_scores.append(metrics.transform_cosine_score(test_hidden, predictions, artist_matrix).mean())\n",
    "    album_scores.append(metrics.transform_cosine_score(test_hidden, predictions, album_matrix).mean())\n",
    "    \n",
    "    cooccur_matrix = train_data.T @ train_data\n",
    "    vibe_scores.append(metrics.transform_cosine_score(test_hidden, predictions, cooccur_matrix).mean())\n",
    "    \n",
    "    popularity_distributions.append(metrics.popularity_bias(predictions, train_data))\n",
    "\n",
    "    print(f\"Fold {iter_num} complete in {time.time() - t:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e202dd",
   "metadata": {},
   "source": [
    "### Popularity Distributions for Selected Distance Exponents\n",
    "\n",
    "The histograms below show the distribution of popularity ranks for songs recommended by the model at three selected values of the exponent $\\alpha$. These plots help visualize how different distance transformations influence the model’s tendency to favor more or less popular songs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9db999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which alpha values (by index) to display\n",
    "selected = [0, 9, 18]  # change this list as needed\n",
    "\n",
    "ncols = len(selected)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(4 * ncols, 6), sharey=True)\n",
    "fig.suptitle(\"Popularity Rank Histograms for Selected Distance Exponents α\", fontsize=16, y=1.05)\n",
    "\n",
    "# Ensure axes is iterable even if ncols = 1\n",
    "if ncols == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, i in zip(axes, selected):\n",
    "    dist = popularity_distributions[i]\n",
    "    hist = []\n",
    "    for key, val in dist.items():\n",
    "        hist.extend([key] * val)\n",
    "\n",
    "    hist = np.array(hist)\n",
    "    mean_val = hist.mean()\n",
    "    var_sd = np.sqrt(hist.var())\n",
    "\n",
    "    ax.hist(hist[hist < 1000], bins=30, edgecolor='black')\n",
    "    ax.set_title(f\"α = {alpha[i]:.2f}\", fontsize=12)\n",
    "    ax.set_xlabel(\"Popularity Rank\", fontsize=10)\n",
    "    if i == selected[0]:\n",
    "        ax.set_ylabel(\"Count\", fontsize=10)\n",
    "    ax.set_xlim(0, 1000)\n",
    "\n",
    "    stats_text = f\"μ = {mean_val:.1f}\\nσ = {var_sd:.1f}\"\n",
    "    ax.text(0.98, 0.95, stats_text, transform=ax.transAxes,\n",
    "            fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73388bca",
   "metadata": {},
   "source": [
    "### Popularity Bias Across Distance Function Variants\n",
    "\n",
    "The following histograms visualize the **popularity ranks** of songs selected by the model under different values of the exponent $\\alpha$ in the distance function:\n",
    "\n",
    "$$f(x) = \\frac{1}{x^\\alpha + 0.5}$$\n",
    "\n",
    "Each subplot corresponds to a specific value of $\\alpha$ used to compute song-to-song similarity. The **x-axis** represents a song's popularity rank (with lower values indicating more popular songs), and the **y-axis** shows how frequently songs of that rank were selected across all predicted playlists.\n",
    "\n",
    "These plots allow us to observe how changing $\\alpha$ influences the model's tendency to favor popular or less popular tracks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d403f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(8, 8), sharex=True, gridspec_kw={'height_ratios': [1, 1.5]})\n",
    "\n",
    "X = alpha\n",
    "\n",
    "# --- Top plot: Vibe Score ---\n",
    "ax1.plot(X, vibe_scores, marker='o', linestyle='-', linewidth=2, color='tab:red')\n",
    "ax1.set_ylabel(\"Vibe Score\", fontsize=12)\n",
    "ax1.set_title(\"Vibe Score vs. Alpha\", fontsize=14)\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# --- Bottom plot: Artist, Album, Accuracy ---\n",
    "ax2.plot(X, artist_scores, marker='o', linestyle='-', linewidth=2, label=\"Artist\")\n",
    "ax2.plot(X, album_scores, marker='o', linestyle='-', linewidth=2, label=\"Album\")\n",
    "ax2.plot(X, accuracy_scores, marker='o', linestyle='-', linewidth=2, label=\"Accuracy\")\n",
    "\n",
    "ax2.set_xlabel(\"Distance Function Alpha\", fontsize=12)\n",
    "ax2.set_ylabel(\"Distribution Match (%)\", fontsize=12)\n",
    "ax2.set_title(\"Artist / Album / Accuracy vs. Alpha\", fontsize=14)\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "ax2.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b3dc6",
   "metadata": {},
   "source": [
    "# Spectral Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc042c7",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Load data and control its size since the volume of data is enormous for some machines.  \n",
    "We use only a small fraction of the playlist-track matrix for this experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc6565",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = data.get_playlist_track_matrix()\n",
    "\n",
    "#control amount of data for slower machines\n",
    "P,_ = train_test_split(P,train_size= 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=100, shuffle=True, random_state=42)\n",
    "\n",
    "artist_matrix = data.get_artist_track_matrix()\n",
    "album_matrix = data.get_album_track_matrix()\n",
    "\n",
    "# Storage for metrics\n",
    "dims = []\n",
    "accuracy_scores = []\n",
    "artist_scores = []\n",
    "album_scores = []\n",
    "vibe_scores = []\n",
    "popularity_distributions = []\n",
    "\n",
    "for iter_num, (train_index, test_index) in enumerate(kf.split(P)):\n",
    "    dim = 50 * (iter_num + 1)\n",
    "    print(f\"Dim: {dim}\")\n",
    "\n",
    "    # Split data\n",
    "    train_data = P[train_index]\n",
    "    test_data = P[test_index]\n",
    "\n",
    "    # Fit model\n",
    "    model = models.Spotify_Spectral_KNN()\n",
    "    t_start = time.time()\n",
    "    model.fit(train_data, dim)\n",
    "    print(\"fit time:\", time.time() - t_start)\n",
    "\n",
    "    # Prepare test split\n",
    "    t_start = time.time()\n",
    "    test_partial, test_hidden = tools.csr_col_split(test_data, 10, 'shuffle')\n",
    "    predictions = model.predict(test_partial, k=25)\n",
    "    print(\"predict time:\", time.time() - t_start)\n",
    "\n",
    "    # Compute scores\n",
    "    dims.append(dim)\n",
    "    accuracy_scores.append(metrics.prediction_accuracy_score(test_hidden, predictions).mean())\n",
    "    artist_scores.append(metrics.transform_cosine_score(test_hidden, predictions, artist_matrix).mean())\n",
    "    album_scores.append(metrics.transform_cosine_score(test_hidden, predictions, album_matrix).mean())\n",
    "    \n",
    "    cooccur_matrix = train_data.T @ train_data\n",
    "    vibe_scores.append(metrics.transform_cosine_score(test_hidden, predictions, cooccur_matrix).mean())\n",
    "    \n",
    "    popularity_distributions.append(metrics.popularity_bias(predictions, train_data))\n",
    "\n",
    "    if iter_num >= 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb00fde",
   "metadata": {},
   "source": [
    "## plot popularity rank historgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7ccbf",
   "metadata": {},
   "source": [
    "### Popularity Bias Across Latent Dimensions in SVD Model\n",
    "\n",
    "The histograms below show the **popularity ranks** of songs recommended by the model when using different values of the latent dimension in an SVD-based embedding.\n",
    "\n",
    "Each subplot corresponds to a particular latent dimensionality used to represent songs and playlists in the model's projection space.\n",
    "\n",
    "- The **x-axis** represents the popularity rank of each predicted song (lower ranks are more popular).\n",
    "- The **y-axis** shows the number of times songs at that rank were selected across all test playlists.\n",
    "- Each plot includes the mean ($\\mu$) and standard deviation ($\\sigma$) of the rank distribution.\n",
    "\n",
    "This visualization helps assess how the choice of embedding dimension influences the model's tendency to recommend more or less popular tracks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which alpha values (by index) to display\n",
    "selected = [0, 9, 18]  # change this list as needed\n",
    "\n",
    "ncols = len(selected)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(4 * ncols, 6), sharey=True)\n",
    "fig.suptitle(\"Popularity Rank Histograms for Selected Dimensions\", fontsize=16, y=1.05)\n",
    "\n",
    "for ax, i in zip(axes, selected):\n",
    "    dist = popularity_distributions[i]\n",
    "    hist = []\n",
    "    for key, val in dist.items():\n",
    "        hist.extend([key] * val)\n",
    "\n",
    "    hist = np.array(hist)\n",
    "    mean_val = hist.mean()\n",
    "    var_sd = np.sqrt(hist.var())\n",
    "\n",
    "    ax.hist(hist[hist < 1000], bins=30, edgecolor='black')\n",
    "    ax.set_title(f\"α = {alpha[i]:.2f}\", fontsize=12)\n",
    "    ax.set_xlabel(\"Popularity Rank\", fontsize=10)\n",
    "    if i == selected[0]:\n",
    "        ax.set_ylabel(\"Count\", fontsize=10)\n",
    "    ax.set_xlim(0, 1000)\n",
    "\n",
    "    stats_text = f\"μ = {mean_val:.1f}\\nσ = {var_sd:.1f}\"\n",
    "    ax.text(0.98, 0.95, stats_text, transform=ax.transAxes,\n",
    "            fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f69c3",
   "metadata": {},
   "source": [
    "### Evaluation Metrics Across Latent Dimensions\n",
    "\n",
    "The plots below summarize the model’s performance as a function of the number of latent dimensions used in the SVD projection.\n",
    "\n",
    "- The **top plot** shows the overall **vibe score**, which measures the similarity between predicted and hidden songs in a co-occurrence-based embedding space.\n",
    "- The **bottom plot** displays the **artist distribution match**, **album distribution match**, and **accuracy** metrics, which assess how well the model preserves artist/album-level structure and exact matches.\n",
    "\n",
    "These metrics help assess how the dimensionality of the latent space influences recommendation quality across different aspects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1becf62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(8, 8), sharex=True, gridspec_kw={'height_ratios': [1, 1.5]})\n",
    "\n",
    "X = dims\n",
    "\n",
    "# --- Top plot: Vibe Score ---\n",
    "ax1.plot(X, vibe_scores, marker='o', linestyle='-', linewidth=2, color='tab:red')\n",
    "ax1.set_ylabel(\"Vibe Score\", fontsize=12)\n",
    "ax1.set_title(\"Vibe Score vs. Alpha\", fontsize=14)\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# --- Bottom plot: Artist, Album, Accuracy ---\n",
    "ax2.plot(X, artist_scores, marker='o', linestyle='-', linewidth=2, label=\"Artist\")\n",
    "ax2.plot(X, album_scores, marker='o', linestyle='-', linewidth=2, label=\"Album\")\n",
    "ax2.plot(X, accuracy_scores, marker='o', linestyle='-', linewidth=2, label=\"Accuracy\")\n",
    "\n",
    "ax2.set_xlabel(\"Distance Function Alpha\", fontsize=12)\n",
    "ax2.set_ylabel(\"Distribution Match (%)\", fontsize=12)\n",
    "ax2.set_title(\"Artist / Album / Accuracy vs. Alpha\", fontsize=14)\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "ax2.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab081ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
